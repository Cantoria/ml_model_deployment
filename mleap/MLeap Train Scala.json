{"paragraphs":[{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1538685558763_-1677671681","id":"20181004-203918_507706861","dateCreated":"2018-10-04T20:39:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:365","text":"import org.apache.spark.ml.feature.VectorAssembler\nimport org.apache.spark.ml.linalg.Vectors\nimport org.apache.spark.sql.types.{IntegerType, DoubleType}\nimport org.apache.spark.ml.Pipeline\nimport org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\nimport org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}\n\nimport ml.combust.bundle.BundleFile\nimport ml.combust.bundle.serializer.SerializationFormat\nimport ml.combust.mleap.spark.SparkSupport._\nimport resource._\n\nimport org.apache.spark.SparkFiles\n\nspark.sparkContext.addFile(\"https://s3-us-west-2.amazonaws.com/mlapi-samples/demo/data/input/iris.csv\")\nval data = spark.read.format(\"csv\").option(\"header\", \"true\").load(SparkFiles.get(\"iris.csv\"))\n\n//data.show()\n//data.printSchema()\n\n// Transform, convert string coloumn to number\n// this transform is not part of the pipeline\nval featureDf = data.select(data(\"sepal_length\").cast(DoubleType).as(\"sepal_length\"),\n                            data(\"sepal_width\").cast(DoubleType).as(\"sepal_width\"),\n                            data(\"petal_width\").cast(DoubleType).as(\"petal_width\"),\n                            data(\"petal_length\").cast(DoubleType).as(\"petal_length\"),\n                            data(\"species\") )\n\n// assember the features\nval assembler = new VectorAssembler()\n  .setInputCols(Array(\"sepal_length\", \"sepal_width\", \"petal_width\", \"petal_length\"))\n  .setOutputCol(\"features\")\n  \nval output = assembler.transform(featureDf)\n\n// create lable and features\nval labelIndexer = new StringIndexer()\n  .setInputCol(\"species\")\n  .setOutputCol(\"indexedLabel\")\n  .fit(output)\n\nval featureIndexer = new VectorIndexer()\n  .setInputCol(\"features\")\n  .setOutputCol(\"indexedFeatures\")\n  .setMaxCategories(4)\n  .fit(output)\n  \n// Split the data into training and test sets (30% held out for testing).\nval Array(trainingData, testData) = featureDf.randomSplit(Array(0.7, 0.3))\n\n// Train a RandomForest model.\nval rf = new RandomForestClassifier()\n  .setLabelCol(\"indexedLabel\")\n  .setFeaturesCol(\"indexedFeatures\")\n  .setNumTrees(10)\n\n// Convert indexed labels back to original labels.\nval labelConverter = new IndexToString()\n  .setInputCol(\"prediction\")\n  .setOutputCol(\"predictedLabel\")\n  .setLabels(labelIndexer.labels)\n\n// Chain indexers and forest in a Pipeline.\nval pipeline = new Pipeline()\n  .setStages(Array(assembler, labelIndexer, featureIndexer, rf, labelConverter))\n\n// Train model. This also runs the indexers.\nval model = pipeline.fit(trainingData)\n\n// Make predictions.\nval predictions = model.transform(testData)\n\n// Select example rows to display.\npredictions.select(\"predictedLabel\", \"species\", \"features\").show(5)\n\n// Select (prediction, true label) and compute test error.\nval evaluator = new MulticlassClassificationEvaluator()\n  .setLabelCol(\"indexedLabel\")\n  .setPredictionCol(\"prediction\")\n  .setMetricName(\"accuracy\")\nval accuracy = evaluator.evaluate(predictions)\nprintln(\"Test Error = \" + (1.0 - accuracy))\n\nval rfModel = model.stages(3).asInstanceOf[RandomForestClassificationModel]\nprintln(\"Learned classification forest model:\\n\" + rfModel.toDebugString)\n\nval pipelineModel = SparkUtil.createPipelineModel(Array(model))\n\nfor(bundle <- managed(BundleFile(\"file:/tmp/mleap-examples/rf\"))) {\n  pipelineModel.writeBundle.format(SerializationFormat.Json).save(bundle)\n}\n","dateUpdated":"2018-10-04T20:48:59+0000","dateFinished":"2018-10-04T20:49:07+0000","dateStarted":"2018-10-04T20:48:59+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.feature.VectorAssembler\nimport org.apache.spark.ml.linalg.Vectors\nimport org.apache.spark.sql.types.{IntegerType, DoubleType}\nimport org.apache.spark.ml.Pipeline\nimport org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\nimport org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}\nimport ml.combust.bundle.BundleFile\nimport ml.combust.bundle.serializer.SerializationFormat\nimport ml.combust.mleap.spark.SparkSupport._\nimport resource._\nimport org.apache.spark.SparkFiles\ndata: org.apache.spark.sql.DataFrame = [sepal_length: string, sepal_width: string ... 3 more fields]\nfeatureDf: org.apache.spark.sql.DataFrame = [sepal_length: double, sepal_width: double ... 3 more fields]\nassembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_362718619683\noutput: org.apache.spark.sql.DataFrame = [sepal_length: double, sepal_width: double ... 4 more fields]\nlabelIndexer: org.apache.spark.ml.feature.StringIndexerModel = strIdx_5342587b9372\nfeatureIndexer: org.apache.spark.ml.feature.VectorIndexerModel = vecIdx_867e834c8e31\ntrainingData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [sepal_length: double, sepal_width: double ... 3 more fields]\ntestData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [sepal_length: double, sepal_width: double ... 3 more fields]\nrf: org.apache.spark.ml.classification.RandomForestClassifier = rfc_f96013e8901d\nlabelConverter: org.apache.spark.ml.feature.IndexToString = idxToStr_b54735b8706e\npipeline: org.apache.spark.ml.Pipeline = pipeline_34fda2c9b007\nmodel: org.apache.spark.ml.PipelineModel = pipeline_34fda2c9b007\npredictions: org.apache.spark.sql.DataFrame = [sepal_length: double, sepal_width: double ... 10 more fields]\n+--------------+-----------+-----------------+\n|predictedLabel|    species|         features|\n+--------------+-----------+-----------------+\n|   Iris Setosa|Iris Setosa|[4.4,3.0,0.2,1.3]|\n|   Iris Setosa|Iris Setosa|[4.4,3.2,0.2,1.3]|\n|   Iris Setosa|Iris Setosa|[4.5,2.3,0.3,1.3]|\n|   Iris Setosa|Iris Setosa|[4.6,3.2,0.2,1.4]|\n|   Iris Setosa|Iris Setosa|[4.7,3.2,0.2,1.3]|\n+--------------+-----------+-----------------+\nonly showing top 5 rows\n\nevaluator: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_7b0986defc00\naccuracy: Double = 0.9574468085106383\nTest Error = 0.04255319148936165\nrfModel: org.apache.spark.ml.classification.RandomForestClassificationModel = RandomForestClassificationModel (uid=rfc_64b3ce99e149) with 10 trees\nLearned classification forest model:\nRandomForestClassificationModel (uid=rfc_64b3ce99e149) with 10 trees\n  Tree 0 (weight 1.0):\n    If (feature 3 <= 1.9)\n     Predict: 1.0\n    Else (feature 3 > 1.9)\n     If (feature 3 <= 4.7)\n      If (feature 2 <= 1.5)\n       Predict: 2.0\n      Else (feature 2 > 1.5)\n       Predict: 0.0\n     Else (feature 3 > 4.7)\n      If (feature 2 <= 1.6)\n       If (feature 2 <= 1.4)\n        Predict: 0.0\n       Else (feature 2 > 1.4)\n        If (feature 3 <= 5.1)\n         Predict: 2.0\n        Else (feature 3 > 5.1)\n         Predict: 0.0\n      Else (feature 2 > 1.6)\n       Predict: 0.0\n  Tree 1 (weight 1.0):\n    If (feature 3 <= 1.9)\n     Predict: 1.0\n    Else (feature 3 > 1.9)\n     If (feature 3 <= 4.8)\n      Predict: 2.0\n     Else (feature 3 > 4.8)\n      If (feature 1 <= 2.7)\n       If (feature 3 <= 4.9)\n        Predict: 2.0\n       Else (feature 3 > 4.9)\n        If (feature 2 <= 1.6)\n         Predict: 0.0\n        Else (feature 2 > 1.6)\n         Predict: 0.0\n      Else (feature 1 > 2.7)\n       If (feature 2 <= 1.5)\n        Predict: 2.0\n       Else (feature 2 > 1.5)\n        Predict: 0.0\n  Tree 2 (weight 1.0):\n    If (feature 3 <= 1.9)\n     Predict: 1.0\n    Else (feature 3 > 1.9)\n     If (feature 2 <= 1.7)\n      If (feature 3 <= 4.9)\n       Predict: 2.0\n      Else (feature 3 > 4.9)\n       If (feature 1 <= 2.2)\n        Predict: 0.0\n       Else (feature 1 > 2.2)\n        Predict: 2.0\n     Else (feature 2 > 1.7)\n      Predict: 0.0\n  Tree 3 (weight 1.0):\n    If (feature 3 <= 1.7)\n     Predict: 1.0\n    Else (feature 3 > 1.7)\n     If (feature 3 <= 4.9)\n      If (feature 0 <= 4.9)\n       Predict: 0.0\n      Else (feature 0 > 4.9)\n       If (feature 2 <= 1.5)\n        Predict: 2.0\n       Else (feature 2 > 1.5)\n        Predict: 0.0\n     Else (feature 3 > 4.9)\n      If (feature 2 <= 1.6)\n       If (feature 3 <= 5.1)\n        Predict: 2.0\n       Else (feature 3 > 5.1)\n        Predict: 0.0\n      Else (feature 2 > 1.6)\n       Predict: 0.0\n  Tree 4 (weight 1.0):\n    If (feature 2 <= 0.6)\n     Predict: 1.0\n    Else (feature 2 > 0.6)\n     If (feature 2 <= 1.5)\n      If (feature 1 <= 2.6)\n       If (feature 3 <= 4.0)\n        Predict: 2.0\n       Else (feature 3 > 4.0)\n        Predict: 0.0\n      Else (feature 1 > 2.6)\n       Predict: 2.0\n     Else (feature 2 > 1.5)\n      If (feature 2 <= 1.7)\n       If (feature 0 <= 4.9)\n        Predict: 0.0\n       Else (feature 0 > 4.9)\n        If (feature 0 <= 6.7)\n         Predict: 2.0\n        Else (feature 0 > 6.7)\n         Predict: 0.0\n      Else (feature 2 > 1.7)\n       Predict: 0.0\n  Tree 5 (weight 1.0):\n    If (feature 2 <= 0.6)\n     Predict: 1.0\n    Else (feature 2 > 0.6)\n     If (feature 2 <= 1.7)\n      If (feature 3 <= 5.1)\n       If (feature 1 <= 2.2)\n        Predict: 0.0\n       Else (feature 1 > 2.2)\n        If (feature 1 <= 2.5)\n         Predict: 2.0\n        Else (feature 1 > 2.5)\n         Predict: 2.0\n      Else (feature 3 > 5.1)\n       Predict: 0.0\n     Else (feature 2 > 1.7)\n      Predict: 0.0\n  Tree 6 (weight 1.0):\n    If (feature 3 <= 1.9)\n     Predict: 1.0\n    Else (feature 3 > 1.9)\n     If (feature 3 <= 4.7)\n      If (feature 0 <= 4.9)\n       Predict: 0.0\n      Else (feature 0 > 4.9)\n       Predict: 2.0\n     Else (feature 3 > 4.7)\n      If (feature 2 <= 1.7)\n       If (feature 3 <= 4.9)\n        Predict: 2.0\n       Else (feature 3 > 4.9)\n        If (feature 1 <= 2.2)\n         Predict: 0.0\n        Else (feature 1 > 2.2)\n         Predict: 0.0\n      Else (feature 2 > 1.7)\n       Predict: 0.0\n  Tree 7 (weight 1.0):\n    If (feature 0 <= 5.4)\n     If (feature 2 <= 0.6)\n      Predict: 1.0\n     Else (feature 2 > 0.6)\n      If (feature 0 <= 4.9)\n       Predict: 0.0\n      Else (feature 0 > 4.9)\n       Predict: 2.0\n    Else (feature 0 > 5.4)\n     If (feature 2 <= 1.7)\n      If (feature 3 <= 1.7)\n       Predict: 1.0\n      Else (feature 3 > 1.7)\n       If (feature 3 <= 4.9)\n        Predict: 2.0\n       Else (feature 3 > 4.9)\n        If (feature 0 <= 6.1)\n         Predict: 0.0\n        Else (feature 0 > 6.1)\n         Predict: 0.0\n     Else (feature 2 > 1.7)\n      Predict: 0.0\n  Tree 8 (weight 1.0):\n    If (feature 3 <= 1.9)\n     Predict: 1.0\n    Else (feature 3 > 1.9)\n     If (feature 3 <= 5.0)\n      If (feature 3 <= 4.4)\n       Predict: 2.0\n      Else (feature 3 > 4.4)\n       If (feature 2 <= 1.5)\n        Predict: 2.0\n       Else (feature 2 > 1.5)\n        If (feature 0 <= 6.2)\n         Predict: 0.0\n        Else (feature 0 > 6.2)\n         Predict: 2.0\n     Else (feature 3 > 5.0)\n      If (feature 2 <= 1.6)\n       If (feature 3 <= 5.1)\n        Predict: 2.0\n       Else (feature 3 > 5.1)\n        Predict: 0.0\n      Else (feature 2 > 1.6)\n       Predict: 0.0\n  Tree 9 (weight 1.0):\n    If (feature 2 <= 0.6)\n     Predict: 1.0\n    Else (feature 2 > 0.6)\n     If (feature 1 <= 3.0)\n      If (feature 3 <= 4.8)\n       If (feature 2 <= 1.5)\n        Predict: 2.0\n       Else (feature 2 > 1.5)\n        Predict: 0.0\n      Else (feature 3 > 4.8)\n       If (feature 2 <= 1.7)\n        If (feature 3 <= 5.1)\n         Predict: 2.0\n        Else (feature 3 > 5.1)\n         Predict: 0.0\n       Else (feature 2 > 1.7)\n        Predict: 0.0\n     Else (feature 1 > 3.0)\n      If (feature 3 <= 4.9)\n       Predict: 2.0\n      Else (feature 3 > 4.9)\n       Predict: 0.0\n\npipelineModel: org.apache.spark.ml.PipelineModel = pipeline_1196a18d1065\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1538685588488_-2102388494","id":"20181004-203948_333246179","dateCreated":"2018-10-04T20:39:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:432","text":"%sh\nls /tmp/mleap-examples/rf/root/pipeline_34fda2c9b007.node/rfc_64b3ce99e149.node\n","dateUpdated":"2018-10-04T20:50:48+0000","dateFinished":"2018-10-04T20:50:48+0000","dateStarted":"2018-10-04T20:50:48+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"model.json\ntree0\ntree1\ntree2\ntree3\ntree4\ntree5\ntree6\ntree7\ntree8\ntree9\n"}]}},{"text":"%sh\ncat  /tmp/mleap-examples/rf/root/pipeline_34fda2c9b007.node/rfc_64b3ce99e149.node/model.json","user":"anonymous","dateUpdated":"2018-10-04T20:51:12+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1538686208725_-42174150","id":"20181004-205008_939065088","dateCreated":"2018-10-04T20:50:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:743","dateFinished":"2018-10-04T20:51:12+0000","dateStarted":"2018-10-04T20:51:12+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"{\n  \"op\": \"random_forest_classifier\",\n  \"attributes\": {\n    \"num_features\": {\n      \"long\": 4\n    },\n    \"num_classes\": {\n      \"long\": 3\n    },\n    \"tree_weights\": {\n      \"double\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n      \"type\": \"list\"\n    },\n    \"trees\": {\n      \"string\": [\"tree0\", \"tree1\", \"tree2\", \"tree3\", \"tree4\", \"tree5\", \"tree6\", \"tree7\", \"tree8\", \"tree9\"],\n      \"type\": \"list\"\n    }\n  }\n}"}]}},{"text":"%sh\n","user":"anonymous","dateUpdated":"2018-10-04T20:51:12+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1538686272819_-1518162875","id":"20181004-205112_70600793","dateCreated":"2018-10-04T20:51:12+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:863"}],"name":"MLeap Train Scala","id":"2DUSDZXJT","angularObjects":{"2DU271S2M:shared_process":[],"2DT7QKZ5U:shared_process":[],"2DU58SXMJ:shared_process":[],"2DRY1PBFX:shared_process":[],"2DRECSPVX:shared_process":[],"2DRE4FJQC:shared_process":[],"2DU4BHYNW:shared_process":[],"2DS8DY9ZK:shared_process":[],"2DREZJUM6:shared_process":[],"2DTTF4DMX:shared_process":[],"2DU4A2EHT:shared_process":[],"2DSW9ZAU2:shared_process":[],"2DR8B3WB4:shared_process":[],"2DUKMFE6M:shared_process":[],"2DRRQ18HA:shared_process":[],"2DRDKYCUF:shared_process":[],"2DUBSVM1F:shared_process":[],"2DTKG1Q7B:shared_process":[],"2DSGP3JXS:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}